{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62ef7945",
   "metadata": {},
   "source": [
    "### Input\n",
    "Definimos a primieira camada e passamos o tamanho da nossa imagem, para sabermos a quantidade de inputs que teremos na nossa rede neural\n",
    "\n",
    "imagem 32x32 cinza:\n",
    "\n",
    "```python\n",
    "layers.Input(32,32,1)\n",
    "```\n",
    "\n",
    "imagem 32x32 cinza:\n",
    "\n",
    "```python\n",
    "layers.Input(32,32,3)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc6f3fe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8657c4",
   "metadata": {},
   "source": [
    "### Flatten\n",
    "Utilizado para achatar a nossa imagem, portanto se temos uma imagem cinza de 32x32 teremos então um array de 1024 (32*32). \n",
    "\n",
    "\n",
    "E para uma imagem 32x32 porém RGB será um array de 3072 (32\\*32\\*3) \n",
    "\n",
    "```python\n",
    "layers.Flatten()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40bd5c3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b34cd2",
   "metadata": {},
   "source": [
    "## \n",
    "\n",
    "### Dense\n",
    "Uma camada de nerônios completamente conectados aos neurônios da camada anterior\n",
    "\n",
    "```python\n",
    "# DEFAULT:\n",
    "layers.Dense(\n",
    "    units,                                  # Quantidade de neurônios na camada\n",
    "    activation,                             # Função de ativação \n",
    "    use_bias=True,                          # Incluir viés/bias (opcional)\n",
    "    kernel_initializer=\"glorot_uniform\",    # Tipo do inicializador dos pesos (opcional)\n",
    "    bias_initializer=\"zeros\",               # Tipo do inicializador dos bias (opcional)\n",
    "    name=None                               # Nome da camada (opcional)\n",
    ")\n",
    "\n",
    "# USE:\n",
    "layers.Dense(128, activation='relu')\n",
    "```\n",
    "\n",
    "![](./img/dense_layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7777609",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0941cb9",
   "metadata": {},
   "source": [
    "### Padding\n",
    "Podemos definir o 'padding' que é o comportamento do filtro dentro da imagem, mas especificamente o comportamento com diferentes tamanhos e como vai lidar com as bordas\n",
    "\n",
    "##### Same\n",
    "adiciona zeros nas bordas somente se necessário para manter o tamanho da saída o mais próximo possível da entrada.\n",
    "Quando stride = 1, o tamanho da saída fica idêntico ao da entrada, e o kernel consegue analisar cada pixel (inclusive bordas, com padding de zeros).\n",
    "\n",
    "##### Valid\n",
    "aplica-se em todo local onde a pool cabe na imagem, ou seja, as bordas nunca são centralizadas por não adicionamos zeros. Evita valores artificiais (zeros) e pega somente informação real da imagem. Usado quando você aceita perder bordas pra ter features mais limpas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5abf56",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e9f216",
   "metadata": {},
   "source": [
    "### Conv2D\n",
    "Convolução 2D (altura e largura)\n",
    "\n",
    "Inicializa filtros com valores aleatórios que durante o treinamento serão ajustados para identificar coisas úteis para o caso\n",
    "\n",
    "```python\n",
    "# DEFAULT:\n",
    "layers.Conv2D(\n",
    "    filters,                                        # Quantidade de filtros\n",
    "    kernel_size=(height,width),                     # Dimensões dos filtros\n",
    "    strides=(stride_height = 1, stride_width = 1),  # Deslocamento, de quantos em quantos pixels o filtro vai ser aplicado\n",
    "    padding=\"valid\",                                # Tipo de ação para as bordas\n",
    ")\n",
    "\n",
    "# USE:\n",
    "layers.Conv2D(16, (3,3))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacc110d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ba0f09",
   "metadata": {},
   "source": [
    "### MaxPooling\n",
    "Delimita uma área e pega o maior valor dessa área. \n",
    "\n",
    "```python\n",
    "# DEFAULT:\n",
    "layers.MaxPooling2D(\n",
    "    pool_size=(2, 2),   # Dimensão da pool\n",
    "    strides=None,       # Deslocamento, de quantos em quantos pixels a pool vai ser aplicada\n",
    "    padding='valid',    # Tipo da ação para as bordas\n",
    ") \n",
    "\n",
    "# USE:\n",
    "layer.MaxPooling2D(pool_size=(3,3), strides=1, padding='same)\n",
    "\n",
    "```\n",
    "![](./img/max_pool.png)\n",
    "\n",
    "\n",
    "\n",
    "![](./img/max_pool_padding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351e4118",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96902c25",
   "metadata": {},
   "source": [
    "## Aplicação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b43f80",
   "metadata": {},
   "source": [
    "### Definindo o modelo\n",
    "\n",
    "#### As imagens no nosso dataset tem dimensões de 28x28 e estão em tons de cinza, portanto temos apenas 1 canal, ou seja, shape=(28,28,1)\n",
    "```python\n",
    "layers.Input(shape=(28,28,1))\n",
    "```\n",
    "    Output: (28, 28, 1)\n",
    "\n",
    "\n",
    "### Aplicamos uma camada de filtros com N neuronios para filtros que recebe a saída da camada anterior (28,28,1) resulta em N imagens de saída\n",
    "```python\n",
    "layers.Conv2D(10, kernel_size=(3,3), strides=(1,1), padding='same')\n",
    "```\n",
    "    Input:  (28, 28, 1)\n",
    "    Output: (28, 28, 10)\n",
    "\n",
    "\n",
    "#### Uma camada para transformar a matriz ou cubo de elementos em um unico array\n",
    "```python\n",
    "layers.Flatten()\n",
    "```\n",
    "    Input:  (28, 28, 10)\n",
    "    Output: (7840,)\n",
    "\n",
    "\n",
    "#### Camada com N neuronios, com ativação de relu, ou seja, para valores negativos a saída é 0. Inicilização aleatória próximo de zero para todos os neurônios\n",
    "```python\n",
    "layers.Dense(64, activations=activations.relu, kernel_initializer=initializer.RandomNormal())\n",
    "```\n",
    "    Input:  (7840,) \n",
    "    Output: 64\n",
    "\n",
    "\n",
    "#### Camada com N neuronios, onde N é a quantidade de saídas possíveis. Com ativação de softmax, ou seja, produz N saídas onde a soma de todas elas resulta em 1.00. Inicilização aleatória próximo de zero para todos os neurônios\n",
    "```python\n",
    "layers.Dense(26, activations=activations.softmax, kernel_initializer=initializer.RandomNormal())\n",
    "```\n",
    "    Input: 64\n",
    "    Output: 26\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab50f4df",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'google.protobuf.internal.api_implementation' has no attribute '_c_module'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m models, layers, activations, initializers\n\u001b[32m      3\u001b[39m model = models.Sequential([\n\u001b[32m      4\u001b[39m     layers.Input(shape=(\u001b[32m28\u001b[39m,\u001b[32m28\u001b[39m,\u001b[32m3\u001b[39m)), \u001b[38;5;66;03m# 28x28x1\u001b[39;00m\n\u001b[32m      5\u001b[39m     layers.Conv2D(\u001b[32m10\u001b[39m, kernel_size=(\u001b[32m3\u001b[39m,\u001b[32m3\u001b[39m), strides=(\u001b[32m1\u001b[39m,\u001b[32m1\u001b[39m), padding=\u001b[33m'\u001b[39m\u001b[33msame\u001b[39m\u001b[33m'\u001b[39m), \u001b[38;5;66;03m# 10 @ 28x28\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     layers.Dense(\u001b[32m24\u001b[39m, activation=activations.softmax, kernel_initializer=initializers.RandomNormal()) \u001b[38;5;66;03m# 24\u001b[39;00m\n\u001b[32m      9\u001b[39m ])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\__init__.py:49\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[32m     47\u001b[39m _tf2.enable()\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_sys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\_api\\v2\\__internal__\\autograph\\__init__.py:8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_sys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimpl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert \u001b[38;5;66;03m# line: 493\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\autograph\\core\\ag_ctx.py:21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minspect\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mthreading\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[32m     25\u001b[39m stacks = threading.local()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\autograph\\utils\\__init__.py:17\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\autograph\\utils\\context_managers.py:19\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcontextlib\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcontrol_dependency_on_returns\u001b[39m(return_value):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\framework\\ops.py:33\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\u001b[32m     12\u001b[39m _runtime_version.ValidateProtobufRuntimeVersion(\n\u001b[32m     13\u001b[39m     _runtime_version.Domain.PUBLIC,\n\u001b[32m     14\u001b[39m     \u001b[32m5\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtensorflow/core/framework/attr_value.proto\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     19\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\protobuf\\symbol_database.py:41\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m api_implementation\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message_factory\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSymbolDatabase\u001b[39;00m():\n\u001b[32m     45\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"A database of Python generated symbols.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\protobuf\\message_factory.py:26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m api_implementation\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_implementation.Type() == \u001b[33m'\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m python_message \u001b[38;5;28;01mas\u001b[39;00m message_impl\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     28\u001b[39m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cpp_message \u001b[38;5;28;01mas\u001b[39;00m message_impl  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\protobuf\\internal\\python_message.py:40\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m descriptor_mod\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message \u001b[38;5;28;01mas\u001b[39;00m message_mod\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m text_format\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# We use \"as\" to avoid name collisions with variables.\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m api_implementation\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\protobuf\\text_format.py:34\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m text_encoding\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m unknown_fields\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[32m     37\u001b[39m __all__ = [\u001b[33m'\u001b[39m\u001b[33mMessageToString\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mParse\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mPrintMessage\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mPrintField\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     38\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mPrintFieldValue\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMerge\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMessageToBytes\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\protobuf\\unknown_fields.py:21\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33;03m\"\"\"Contains Unknown Fields APIs.\u001b[39;00m\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m \u001b[33;03mSimple usage example:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \u001b[33;03m    data = unknown_field.data\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m api_implementation\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mapi_implementation\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_c_module\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m     22\u001b[39m   UnknownFieldSet = api_implementation._c_module.UnknownFieldSet  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mAttributeError\u001b[39m: module 'google.protobuf.internal.api_implementation' has no attribute '_c_module'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models, layers, activations, initializers\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(28,28,3)), # 28x28x1\n",
    "    layers.Conv2D(10, kernel_size=(3,3), strides=(1,1), padding='same'), # 10 @ 28x28\n",
    "    layers.Flatten(), # 7840\n",
    "    layers.Dense(64, activation=activations.relu, kernel_initializer=initializers.RandomNormal()), # 64\n",
    "    layers.Dense(24, activation=activations.softmax, kernel_initializer=initializers.RandomNormal()) # 24\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff69035",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d782a353",
   "metadata": {},
   "source": [
    "### Compilando\n",
    "\n",
    "##### Optimizer\n",
    "Quando o modelo realiza uma previsão calculamos o Erro, o optimizer é como vamos ajustar os pesos com base no Erro calculado\n",
    "\n",
    "- SGD (Stochastic Gradient Descent)\tSimples e direto, ajusta pesos gradualmente. Pode ser lento.\n",
    "- Adam\tMistura de momentum + adaptativo. É o mais usado, aprende mais rápido e estável.\n",
    "- RMSprop\tParecido com Adam, usado muito em redes recorrentes.\n",
    "- Adagrad, Adadelta\tAdaptam a taxa de aprendizado por parâmetro, mas menos usados hoje.\n",
    "\n",
    "\n",
    "\n",
    "Momentum: Reduz as oscilações do resultado da melhora do erro. Guarda o histórico dos valores resultantes e utiliza a \"velocidade\" e a direção que está indo para calcular o novo.\n",
    "\n",
    "Apatativo: Utiliza sua própria taxa de aprendizado. Se um peso sempre erra muito, o otimizador reduz a taxa pra não oscilar demais. Se um peso erra pouco o otimizador aumenta a taxa pra aprender mais rápido.\n",
    "\n",
    "Rede recorrente: (Recurrent Neural Netword, RNN) Uma rede feita pra funcionar com dados em sequência. Ex: \"O monstro amarelo tem um olho\". Treina percorrendo cada palavra e considerando as frase montada antes da palavra do indice atual\n",
    "\n",
    "\n",
    "![](./img/optimizers.png)\n",
    "\n",
    "\n",
    "##### Loss\n",
    "Define como vai ser calculado o erro com a predição. Vai depender da situação analisada:\n",
    "\n",
    "| Tipo de problema                     | Função de perda mais usada            | String / Classe                        |\n",
    "|--------------------------------------|---------------------------------------|----------------------------------------|\n",
    "| Classificação binária                | Binary Crossentropy                   | `'binary_crossentropy'`                |\n",
    "| Classificação multi-classe (one-hot) | Categorical Crossentropy              | `'categorical_crossentropy'`           |\n",
    "| Classificação multi-classe (inteiro) | Sparse Categorical Crossentropy       | `'sparse_categorical_crossentropy'`    |\n",
    "| Regressão                            | Mean Squared Error (MSE)              | `'mse'`, `'mean_squared_error'`        |\n",
    "\n",
    "\n",
    "##### Metrics\n",
    "Não altera o funcionamento em si mas podemos definir o que queremos acompanhar enquanto o modelo estiver treinando\n",
    "| Métrica | Classe / String | Descrição |\n",
    "|----------|-----------------|------------|\n",
    "| `Accuracy` | `'accuracy'` / `metrics.Accuracy()` | Calcula a proporção de predições corretas em relação ao total. |\n",
    "| `BinaryAccuracy` | `'binary_accuracy'` / `metrics.BinaryAccuracy()` | Mede a acurácia em tarefas de classificação binária. |\n",
    "| `CategoricalAccuracy` | `'categorical_accuracy'` / `metrics.CategoricalAccuracy()` | Mede a acurácia considerando rótulos one-hot. |\n",
    "| `SparseCategoricalAccuracy` | `'sparse_categorical_accuracy'` / `metrics.SparseCategoricalAccuracy()` | Mede a acurácia considerando rótulos inteiros (não one-hot). |\n",
    "| `Precision` | `'Precision'` / `metrics.Precision()` | Proporção de predições positivas que realmente são positivas. |\n",
    "| `Recall` | `'Recall'` / `metrics.Recall()` | Proporção de instâncias positivas que foram corretamente identificadas. |\n",
    "| `AUC` | `'AUC'` / `metrics.AUC()` | Calcula a área sob a curva ROC (Receiver Operating Characteristic). |\n",
    "| `TopKCategoricalAccuracy` | `'top_k_categorical_accuracy'` / `metrics.TopKCategoricalAccuracy(k=5)` | Considera correta a predição se o rótulo verdadeiro estiver entre as *k* classes mais prováveis. |\n",
    "| `F1Score` | `metrics.F1Score()` *(TensorFlow ≥ 2.11)* | Combina *Precision* e *Recall* na fórmula F1 = 2·(P·R)/(P+R). |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a463c565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers, losses, metrics\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "model.compile(\n",
    "    optimizer = optimizers.Adam(\n",
    "        learning_rate = lr    \n",
    "    ),\n",
    "    loss = losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [ metrics.sparse_categorical_accuracy ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1a9f8f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9244a8c",
   "metadata": {},
   "source": [
    "# Lendo o dataset\n",
    "\n",
    "```python\n",
    "utils.image_dataset_from_directory(\n",
    "    directory           \n",
    "    image_size\n",
    "    shuffle\n",
    "    seed\n",
    "    batch_size\n",
    "    subset\n",
    "    validation\n",
    "    label_mode\n",
    ")\n",
    "```\n",
    "\n",
    "#### directory\n",
    "    Diretório onde se encontra nosso dataset\n",
    "\n",
    "#### image_size\n",
    "    Tamanho o qual as imagens serão lidas. Caso não tenham o tamanho infomrado elas serão redimensionadas.\n",
    "    Sendo Z e Y os valores definidos. No processamento das imagens vai ser convertido N x M -> Z x Y\n",
    "\n",
    "\n",
    "#### shuffle\n",
    "    Mistura as imagens do dataset mas sem perder a coerência\n",
    "\n",
    "#### seed\n",
    "    Garante que se rodar o código de novo, o embaralhamento seja igual.\n",
    "\n",
    "#### batch_size\n",
    "    Onde definimos o tamanho dos pacotes de dados/imagens que serão usados na hora do treinamento\n",
    "\n",
    "#### validation & subset\n",
    "    validation\n",
    "    Define o tamanho da parte que será dividida como validação do dataset\n",
    "\n",
    "    subset \n",
    "    Define qual parte da divisão este é ('validation' | 'training')\n",
    "\n",
    "```python\n",
    "train = utils.image_dataset_from_directory(\n",
    "    ...,\n",
    "    validation= 0.2,\n",
    "    subset= 'training',\n",
    "    ...\n",
    ")\n",
    "\n",
    "test = utils.image_dataset_from_directory(\n",
    "    ...,\n",
    "    validation= 0.2,\n",
    "    subset= 'validation',\n",
    "    ...\n",
    ")\n",
    "```\n",
    "Como nosso validation é definido com 20% dos nossos dados, o subset validation tem 20% dos dados e o subset training todo o resto\n",
    "\n",
    "#### label_mode\n",
    "Define o formato dos rótulos retornados junto com as imagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6aee3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27455 files belonging to 24 classes.\n",
      "Found 7172 files belonging to 24 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import utils\n",
    "\n",
    "path = './Data'\n",
    "batch_size = 64\n",
    "\n",
    "train = utils.image_dataset_from_directory(\n",
    "    directory=path + '/Train',\n",
    "    shuffle = True,\n",
    "    seed = 1,\n",
    "    image_size = (28,28),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "test = utils.image_dataset_from_directory(\n",
    "    directory=path + '/Test',\n",
    "    shuffle = True,\n",
    "    seed = 1,\n",
    "    image_size = (28,28),\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5678a552",
   "metadata": {},
   "source": [
    "**No caso a cima não foi necessário utilizar validation e subset pois já temos dois datasets já separados por validação e treino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aa43f1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b1ba3f",
   "metadata": {},
   "source": [
    "# Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e63c553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - loss: 0.4547 - sparse_categorical_accuracy: 0.8427 - val_loss: 0.7380 - val_sparse_categorical_accuracy: 0.7765\n",
      "Epoch 2/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - loss: 0.4432 - sparse_categorical_accuracy: 0.8445 - val_loss: 0.7700 - val_sparse_categorical_accuracy: 0.7747\n",
      "Epoch 3/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m980s\u001b[0m 2s/step - loss: 0.4187 - sparse_categorical_accuracy: 0.8547 - val_loss: 0.8060 - val_sparse_categorical_accuracy: 0.7520\n",
      "Epoch 4/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - loss: 0.4082 - sparse_categorical_accuracy: 0.8595 - val_loss: 0.7368 - val_sparse_categorical_accuracy: 0.7886\n",
      "Epoch 5/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 34ms/step - loss: 0.3825 - sparse_categorical_accuracy: 0.8674 - val_loss: 0.6883 - val_sparse_categorical_accuracy: 0.7955\n",
      "Epoch 6/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 42ms/step - loss: 0.3889 - sparse_categorical_accuracy: 0.8666 - val_loss: 0.6653 - val_sparse_categorical_accuracy: 0.8104\n",
      "Epoch 7/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - loss: 0.3639 - sparse_categorical_accuracy: 0.8738 - val_loss: 0.7157 - val_sparse_categorical_accuracy: 0.7875\n",
      "Epoch 8/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 38ms/step - loss: 0.3603 - sparse_categorical_accuracy: 0.8753 - val_loss: 0.6550 - val_sparse_categorical_accuracy: 0.8204\n",
      "Epoch 9/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 34ms/step - loss: 0.3502 - sparse_categorical_accuracy: 0.8821 - val_loss: 0.6588 - val_sparse_categorical_accuracy: 0.8175\n",
      "Epoch 10/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 35ms/step - loss: 0.3371 - sparse_categorical_accuracy: 0.8818 - val_loss: 0.7338 - val_sparse_categorical_accuracy: 0.8100\n",
      "Epoch 11/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - loss: 0.3362 - sparse_categorical_accuracy: 0.8833 - val_loss: 0.7537 - val_sparse_categorical_accuracy: 0.8042\n",
      "Epoch 12/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 35ms/step - loss: 0.3140 - sparse_categorical_accuracy: 0.8910 - val_loss: 0.6842 - val_sparse_categorical_accuracy: 0.8171\n",
      "Epoch 13/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - loss: 0.3147 - sparse_categorical_accuracy: 0.8917 - val_loss: 0.7445 - val_sparse_categorical_accuracy: 0.8049\n",
      "Epoch 13: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2bb7bc066c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "\n",
    "patience = 5\n",
    "epochs = 100\n",
    "\n",
    "model.fit(\n",
    "    train,\n",
    "    validation_data = test,\n",
    "    epochs = epochs,\n",
    "    verbose = True,\n",
    "    \n",
    "    callbacks = [\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor = 'val_loss',\n",
    "            patience = patience,\n",
    "            verbose = True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de7265e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9f5605",
   "metadata": {},
   "source": [
    "# Melhorando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d37aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - loss: 2.7702 - sparse_categorical_accuracy: 0.1365 - val_loss: 2.2300 - val_sparse_categorical_accuracy: 0.2653\n",
      "Epoch 2/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - loss: 2.2726 - sparse_categorical_accuracy: 0.2577 - val_loss: 1.8784 - val_sparse_categorical_accuracy: 0.3794\n",
      "Epoch 3/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - loss: 1.9416 - sparse_categorical_accuracy: 0.3468 - val_loss: 1.6581 - val_sparse_categorical_accuracy: 0.4274\n",
      "Epoch 4/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 35ms/step - loss: 1.6248 - sparse_categorical_accuracy: 0.4499 - val_loss: 1.3035 - val_sparse_categorical_accuracy: 0.5470\n",
      "Epoch 5/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - loss: 1.3697 - sparse_categorical_accuracy: 0.5306 - val_loss: 1.1263 - val_sparse_categorical_accuracy: 0.6106\n",
      "Epoch 6/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 162ms/step - loss: 1.1526 - sparse_categorical_accuracy: 0.6011 - val_loss: 1.0144 - val_sparse_categorical_accuracy: 0.6424\n",
      "Epoch 7/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 170ms/step - loss: 1.0087 - sparse_categorical_accuracy: 0.6502 - val_loss: 0.9381 - val_sparse_categorical_accuracy: 0.6676\n",
      "Epoch 8/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 36ms/step - loss: 0.9110 - sparse_categorical_accuracy: 0.6829 - val_loss: 0.9149 - val_sparse_categorical_accuracy: 0.6946\n",
      "Epoch 9/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 24ms/step - loss: 0.8156 - sparse_categorical_accuracy: 0.7160 - val_loss: 0.8924 - val_sparse_categorical_accuracy: 0.6771\n",
      "Epoch 10/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - loss: 0.7481 - sparse_categorical_accuracy: 0.7361 - val_loss: 0.8419 - val_sparse_categorical_accuracy: 0.7206\n",
      "Epoch 11/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 33ms/step - loss: 0.7048 - sparse_categorical_accuracy: 0.7517 - val_loss: 0.8102 - val_sparse_categorical_accuracy: 0.7337\n",
      "Epoch 12/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 32ms/step - loss: 0.6511 - sparse_categorical_accuracy: 0.7707 - val_loss: 0.7786 - val_sparse_categorical_accuracy: 0.7421\n",
      "Epoch 13/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 33ms/step - loss: 0.6098 - sparse_categorical_accuracy: 0.7863 - val_loss: 0.7097 - val_sparse_categorical_accuracy: 0.7786\n",
      "Epoch 14/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 31ms/step - loss: 0.5728 - sparse_categorical_accuracy: 0.7980 - val_loss: 0.7322 - val_sparse_categorical_accuracy: 0.7698\n",
      "Epoch 15/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 32ms/step - loss: 0.5451 - sparse_categorical_accuracy: 0.8117 - val_loss: 0.7528 - val_sparse_categorical_accuracy: 0.7681\n",
      "Epoch 16/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 31ms/step - loss: 0.5087 - sparse_categorical_accuracy: 0.8228 - val_loss: 0.7357 - val_sparse_categorical_accuracy: 0.7655\n",
      "Epoch 17/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 31ms/step - loss: 0.4970 - sparse_categorical_accuracy: 0.8292 - val_loss: 0.7391 - val_sparse_categorical_accuracy: 0.7745\n",
      "Epoch 18/100\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - loss: 0.4725 - sparse_categorical_accuracy: 0.8370 - val_loss: 0.7529 - val_sparse_categorical_accuracy: 0.7672\n",
      "Epoch 18: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2bb7d32b5c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import models, layers, activations, initializers\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(28,28,3)), \n",
    "    \n",
    "    layers.Resizing(28,28),\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.RandomRotation((-0.2, 0.2)),\n",
    "\n",
    "    layers.Conv2D(10, kernel_size=(3,3), strides=(1,1), padding='same'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "\n",
    "    layers.Dense(64, activation=activations.relu, kernel_initializer=initializers.RandomNormal()),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(64, activation=activations.relu, kernel_initializer=initializers.RandomNormal()),\n",
    "    layers.Dense(24, activation=activations.softmax, kernel_initializer=initializers.RandomNormal())\n",
    "])\n",
    "\n",
    "from tensorflow.keras import optimizers, losses, metrics\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "model.compile(\n",
    "    optimizer = optimizers.Adam(\n",
    "        learning_rate = lr    \n",
    "    ),\n",
    "    loss = losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [ metrics.sparse_categorical_accuracy ]\n",
    ")\n",
    "\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "patience = 5\n",
    "epochs = 100\n",
    "model_path = \"./model.keras\"\n",
    "\n",
    "model.fit(\n",
    "    train,\n",
    "    validation_data = test,\n",
    "    epochs = epochs,\n",
    "    verbose = True,\n",
    "    \n",
    "    callbacks = [\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor = 'val_loss',\n",
    "            patience = patience,\n",
    "            verbose = 1\n",
    "        ),\n",
    "        callbacks .ModelCheckpoint(\n",
    "            filepath = model_path,\n",
    "            save_weights_only = False,\n",
    "            monitor = 'loss',\n",
    "            mode = 'min',\n",
    "            save_best_only = True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
